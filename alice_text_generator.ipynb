{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alice_text_generator.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOqPvGwWqRBFFSFjBUliB3W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahima-c/DL-Problem-solution/blob/main/alice_text_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxzfKdnrifjm"
      },
      "source": [
        "**Character Text Genrator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoFSIBc9jXeV"
      },
      "source": [
        "As always, we will first import the necessary libraries and set up some constants. Here the DATA_DIR points to a data folder under the location where you downloaded the source code for this chapter. The CHECKPOINT_DIR is the location, a folder checkpoints under the data folder, where we will save the weights of the model at the end of every 10 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxepgyu2gj1j"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import shutil\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFOSxWUbjeNg"
      },
      "source": [
        "Next we download and prepare the data for our network to consume. The texts of both books are publicly available from the Project Gutenberg website. The tf.keras.utils.get_file() function will check to see whether the file is already downloaded to your local drive, and if not, it will download to a datasets folder under the location of the code. We also preprocess the input a little here, removing newline and byte order mark characters from the text. This step will create the texts variable, a flat list of characters for these two books:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aeURR5bjjZ9"
      },
      "source": [
        "Next, we will create our vocabulary. In our case, our vocabulary contains 90 unique characters, composed of uppercase and lowercase alphabets, numbers, and special characters. We also create some mapping dictionaries to convert each vocabulary character to a unique integer and vice versa. As noted earlier, the input and output of the network is a sequence of characters. However, the actual input and output of the network are sequences of integers, and we will use these mapping dictionaries to handle this conversion:\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlqjmqYajlyx"
      },
      "source": [
        "The next step is to use these mapping dictionaries to convert our character sequence input into an integer sequence, and then into a TensorFlow dataset. Each of our sequences is going to be 100 characters long, with the output being offset from the input by 1 character position. We first batch the dataset into slices of 101 characters, then apply the split_train_labels() function to every element of the dataset to create our sequences dataset, which is a dataset of tuples of two elements, each element of the tuple being a vector of size 100 and type tf.int64. We then shuffle these sequences and then create batches of 64 tuples each for input to our network. Each element of the dataset is now a tuple consisting of a pair of matrices, each of size (64, 100) and type tf.int64:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJPsW_1AjmFR"
      },
      "source": [
        "We are now ready to define our network. As before, we define our network as a subclass of tf.keras.Model as shown next. The network is fairly simple; it takes as input a sequence of integers of size 100 (num_timesteps) and passes them through an Embedding layer so that each integer in the sequence is converted to a vector of size 256 (embedding_dim). So, assuming a batch size of 64, for our input sequence of size (64, 100), the output of the Embedding layer is a matrix of shape (64, 100, 256).\r\n",
        "\r\n",
        "The next layer is the RNN layer with 100 time steps. The implementation of RNN chosen is a GRU. This GRU layer will take, at each of its time steps, a vector of size (256,) and output a vector of shape (1024,) (rnn_output_dim). Note also that the RNN is stateful, which means that the hidden state output from the previous training epoch will be used as input to the current epoch. The return_sequences=True flag also indicates that the RNN will output at each of the time steps rather than an aggregate output at the last time steps.\r\n",
        "\r\n",
        "Finally, each of the time steps will emit a vector of shape (1024,) into a Dense layer that outputs a vector of shape (90,) (vocab_size). The output from this layer will be a tensor of shape (64, 100, 90). Each position in the output vector corresponds to a character in our vocabulary, and the values correspond to the probability of that character occurring at that output position:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWyN2G3MjsKG"
      },
      "source": [
        "Next we define a loss function and compile our model. We will use the sparse categorical cross-entropy as our loss function because that is the standard loss function to use when our inputs and outputs are sequences of integers. For the optimizer, we will choose the Adam optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ-2LUutgnxI"
      },
      "source": [
        "DATA_DIR = \"./data\"\r\n",
        "CHECKPOINT_DIR = os.path.join(DATA_DIR, \"checkpoints\")\r\n",
        "LOG_DIR = os.path.join(DATA_DIR, \"logs\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuuRMuXxgvKI"
      },
      "source": [
        "def clean_logs():\r\n",
        "    shutil.rmtree(CHECKPOINT_DIR, ignore_errors=True)\r\n",
        "    shutil.rmtree(LOG_DIR, ignore_errors=True)\r\n",
        "\r\n",
        "\r\n",
        "def download_and_read(urls):\r\n",
        "    texts = []\r\n",
        "    for i, url in enumerate(urls):\r\n",
        "        p = tf.keras.utils.get_file(\"ex1-{:d}.txt\".format(i), url,\r\n",
        "            cache_dir=\".\")\r\n",
        "        text = open(p, mode=\"r\", encoding=\"utf-8\").read()\r\n",
        "        # remove byte order mark\r\n",
        "        text = text.replace(\"\\ufeff\", \"\")\r\n",
        "        # remove newlines\r\n",
        "        text = text.replace('\\n', ' ')\r\n",
        "        text = re.sub(r'\\s+', \" \", text)\r\n",
        "        # add it to the list\r\n",
        "        texts.extend(text)\r\n",
        "    return texts\r\n",
        "\r\n",
        "\r\n",
        "def split_train_labels(sequence):\r\n",
        "    input_seq = sequence[0:-1]\r\n",
        "    output_seq = sequence[1:]\r\n",
        "    return input_seq, output_seq\r\n",
        "\r\n",
        "\r\n",
        "class CharGenModel(tf.keras.Model):\r\n",
        "\r\n",
        "    def __init__(self, vocab_size, num_timesteps, \r\n",
        "            embedding_dim, **kwargs):\r\n",
        "        super(CharGenModel, self).__init__(**kwargs)\r\n",
        "        self.embedding_layer = tf.keras.layers.Embedding(\r\n",
        "            vocab_size,\r\n",
        "            embedding_dim\r\n",
        "        )\r\n",
        "        self.rnn_layer = tf.keras.layers.GRU(\r\n",
        "            num_timesteps,\r\n",
        "            recurrent_initializer=\"glorot_uniform\",\r\n",
        "            recurrent_activation=\"sigmoid\",\r\n",
        "            stateful=True,\r\n",
        "            return_sequences=True\r\n",
        "        )\r\n",
        "        self.dense_layer = tf.keras.layers.Dense(vocab_size)\r\n",
        "\r\n",
        "    def call(self, x):\r\n",
        "        x = self.embedding_layer(x)\r\n",
        "        x = self.rnn_layer(x)\r\n",
        "        x = self.dense_layer(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "def loss(labels, predictions):\r\n",
        "    return tf.losses.sparse_categorical_crossentropy(\r\n",
        "        labels,\r\n",
        "        predictions,\r\n",
        "        from_logits=True\r\n",
        "    )\r\n",
        "\r\n",
        "\r\n",
        "def generate_text(model, prefix_string, char2idx, idx2char,\r\n",
        "        num_chars_to_generate=1000, temperature=1.0):\r\n",
        "    input = [char2idx[s] for s in prefix_string]\r\n",
        "    input = tf.expand_dims(input, 0)\r\n",
        "    text_generated = []\r\n",
        "    model.reset_states()\r\n",
        "    for i in range(num_chars_to_generate):\r\n",
        "        preds = model(input)\r\n",
        "        preds = tf.squeeze(preds, 0) / temperature\r\n",
        "        # predict char returned by model\r\n",
        "        pred_id = tf.random.categorical(preds, num_samples=1)[-1, 0].numpy()\r\n",
        "        text_generated.append(idx2char[pred_id])\r\n",
        "        # pass the prediction as the next input to the model\r\n",
        "        input = tf.expand_dims([pred_id], 0)\r\n",
        "\r\n",
        "    return prefix_string + \"\".join(text_generated)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeAISdAdg2JU"
      },
      "source": [
        "# download and read into local data structure (list of chars)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6rQLmiCgzbM",
        "outputId": "01991c54-9f18-4214-e858-7aed2a614e20"
      },
      "source": [
        "texts = download_and_read([\r\n",
        "    \"http://www.gutenberg.org/cache/epub/28885/pg28885.txt\",\r\n",
        "    \"https://www.gutenberg.org/files/12/12-0.txt\"\r\n",
        "])\r\n",
        "clean_logs()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://www.gutenberg.org/cache/epub/28885/pg28885.txt\n",
            "180224/177479 [==============================] - 0s 2us/step\n",
            "Downloading data from https://www.gutenberg.org/files/12/12-0.txt\n",
            "196608/193784 [==============================] - 0s 2us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikJ5TvSeg7vx",
        "outputId": "ef1a01c7-b7be-4231-d302-8520e25a7d58"
      },
      "source": [
        "# create the vocabulary\r\n",
        "vocab = sorted(set(texts))\r\n",
        "print(\"vocab size: {:d}\".format(len(vocab)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-ZrtZGKg70F"
      },
      "source": [
        "# create mapping from vocab chars to ints\r\n",
        "char2idx = {c:i for i, c in enumerate(vocab)}\r\n",
        "idx2char = {i:c for c, i in char2idx.items()}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OacuPRFng730"
      },
      "source": [
        "# numericize the texts\r\n",
        "texts_as_ints = np.array([char2idx[c] for c in texts])\r\n",
        "data = tf.data.Dataset.from_tensor_slices(texts_as_ints)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-0o1jCdg77y"
      },
      "source": [
        "# number of characters to show before asking for prediction\r\n",
        "# sequences: [None, 100]\r\n",
        "seq_length = 100\r\n",
        "sequences = data.batch(seq_length + 1, drop_remainder=True)\r\n",
        "sequences = sequences.map(split_train_labels)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZicjwBrhGhX",
        "outputId": "33ea77b0-1b61-4778-b9ec-33d2bbe613fb"
      },
      "source": [
        "# print out input and output to see what they look like\r\n",
        "for input_seq, output_seq in sequences.take(1):\r\n",
        "    print(\"input:[{:s}]\".format(\r\n",
        "        \"\".join([idx2char[i] for i in input_seq.numpy()])))\r\n",
        "    print(\"output:[{:s}]\".format(\r\n",
        "        \"\".join([idx2char[i] for i in output_seq.numpy()])))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input:[Project Gutenberg's Alice's Adventures in Wonderland, by Lewis Carroll This eBook is for the use of ]\n",
            "output:[roject Gutenberg's Alice's Adventures in Wonderland, by Lewis Carroll This eBook is for the use of a]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNJHGziphGjn",
        "outputId": "586935a4-5255-44de-b57e-a048c585fe26"
      },
      "source": [
        "# set up for training\r\n",
        "# batches: [None, 64, 100]\r\n",
        "batch_size = 64\r\n",
        "steps_per_epoch = len(texts) // seq_length // batch_size\r\n",
        "dataset = sequences.shuffle(10000).batch(batch_size, drop_remainder=True)\r\n",
        "print(dataset)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLOAKu9qhGms",
        "outputId": "479fdd4c-4a99-44ac-f138-8df0ef729a81"
      },
      "source": [
        "# define network\r\n",
        "vocab_size = len(vocab)\r\n",
        "embedding_dim = 256\r\n",
        "\r\n",
        "model = CharGenModel(vocab_size, seq_length, embedding_dim)\r\n",
        "model.build(input_shape=(batch_size, seq_length))\r\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"char_gen_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  23040     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    multiple                  107400    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  9090      \n",
            "=================================================================\n",
            "Total params: 139,530\n",
            "Trainable params: 139,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTb5qG8lhGpZ",
        "outputId": "c60a1605-5187-4ae4-e770-a4a1beb7c6db"
      },
      "source": [
        "# try running some data through the model to validate dimensions\r\n",
        "for input_batch, label_batch in dataset.take(1):\r\n",
        "    pred_batch = model(input_batch)\r\n",
        "\r\n",
        "print(pred_batch.shape)\r\n",
        "assert(pred_batch.shape[0] == batch_size)\r\n",
        "assert(pred_batch.shape[1] == seq_length)\r\n",
        "assert(pred_batch.shape[2] == vocab_size)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 90)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fx1mMaIhGts"
      },
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(), loss=loss)\r\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65sdNZfmtaEa"
      },
      "source": [
        "Finally, we are ready to run our training and evaluation loop. As mentioned earlier, we will train our network for 50 epochs, and at every 10 epoch intervals, we will try to generate some text with the model trained so far. Our prefix at each stage is the string \"Alice.\" Notice that in order to accommodate a single string prefix, we save the weights after every 10 epochs and build a separate generative model with these weights but with an input shape with a batch size of 1. Here is the code to do this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbspuKhohGwe",
        "outputId": "a428c83f-dd2c-4dc6-a5a7-98da46a98d4c"
      },
      "source": [
        "# we will train our model for 50 epochs, and after every 10 epochs\r\n",
        "# we want to see how well it will generate text\r\n",
        "num_epochs = 50\r\n",
        "for i in range(num_epochs // 10):\r\n",
        "    model.fit(\r\n",
        "        dataset.repeat(),\r\n",
        "        epochs=10,\r\n",
        "        steps_per_epoch=steps_per_epoch\r\n",
        "        # callbacks=[checkpoint_callback, tensorboard_callback]\r\n",
        "    )\r\n",
        "    checkpoint_file = os.path.join(\r\n",
        "        CHECKPOINT_DIR, \"model_epoch_{:d}\".format(i+1))\r\n",
        "    model.save_weights(checkpoint_file)\r\n",
        "\r\n",
        "    # create a generative model using the trained model so far\r\n",
        "    gen_model = CharGenModel(vocab_size, seq_length, embedding_dim)\r\n",
        "    gen_model.load_weights(checkpoint_file)\r\n",
        "    gen_model.build(input_shape=(1, seq_length))\r\n",
        "\r\n",
        "    print(\"after epoch: {:d}\".format(i+1)*10)\r\n",
        "    print(generate_text(gen_model, \"Alice \", char2idx, idx2char))\r\n",
        "    print(\"---\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "54/54 [==============================] - 11s 177ms/step - loss: 3.9725\n",
            "Epoch 2/10\n",
            "54/54 [==============================] - 10s 177ms/step - loss: 2.8369\n",
            "Epoch 3/10\n",
            "54/54 [==============================] - 10s 177ms/step - loss: 2.5055\n",
            "Epoch 4/10\n",
            "54/54 [==============================] - 10s 177ms/step - loss: 2.3582\n",
            "Epoch 5/10\n",
            "54/54 [==============================] - 10s 178ms/step - loss: 2.2401\n",
            "Epoch 6/10\n",
            "54/54 [==============================] - 10s 176ms/step - loss: 2.1484\n",
            "Epoch 7/10\n",
            "54/54 [==============================] - 9s 175ms/step - loss: 2.0691\n",
            "Epoch 8/10\n",
            "54/54 [==============================] - 10s 179ms/step - loss: 1.9976\n",
            "Epoch 9/10\n",
            "54/54 [==============================] - 10s 177ms/step - loss: 1.9402\n",
            "Epoch 10/10\n",
            "54/54 [==============================] - 10s 179ms/step - loss: 1.8907\n",
            "after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1\n",
            "Alice as ho in the Doupted as!' “Do ked; They she sair con a tand thy Alice one wand there. \"Whisurse \"To eardlusting agann’t a link. ‘But that beterpswingon is by by,\" save shat bowisemen, at any ge ook--thiadss had her net is wall mome it,\" she Pake’t Alice cat shan'tter pucthen’s a mister knequally. The not’s wery is if andered lied a she snot it and wing of in crssiresel/y ofon iok of a nome Prinjerned ribke to briement son a sigen!’ stooklly?\" ongani corpented agrely yees on the Queensh of the could bed bis mut suress so that the het_ onmily’nk th oute eByow she Died intersever mar.’ Ony:!’ Wh! They sompsienter, atkith Mads, ad so dozing, you’se a dreatincther in she said frovin,’ sither bun kingring to grioning!\" tnouldnded no must, ‘I the was oveavist find yeal foon abotic moodedf Drowe do counself!’ ‘Theinie-ting wand is, wither to hers befantly: (Whice of with sarkes beaply ong mare whonkes, the of the waster pact coutcerted it ane it suirs prorofibe that lion, and though ryLEo quee\n",
            "---\n",
            "Epoch 1/10\n",
            "54/54 [==============================] - 10s 176ms/step - loss: 1.8393\n",
            "Epoch 2/10\n",
            "54/54 [==============================] - 10s 180ms/step - loss: 1.8022\n",
            "Epoch 3/10\n",
            "54/54 [==============================] - 10s 178ms/step - loss: 1.7678\n",
            "Epoch 4/10\n",
            "54/54 [==============================] - 10s 179ms/step - loss: 1.7381\n",
            "Epoch 5/10\n",
            "54/54 [==============================] - 10s 177ms/step - loss: 1.7135\n",
            "Epoch 6/10\n",
            "54/54 [==============================] - 10s 177ms/step - loss: 1.6887\n",
            "Epoch 7/10\n",
            "54/54 [==============================] - 10s 178ms/step - loss: 1.6598\n",
            "Epoch 8/10\n",
            "54/54 [==============================] - 10s 178ms/step - loss: 1.6443\n",
            "Epoch 9/10\n",
            "54/54 [==============================] - 9s 175ms/step - loss: 1.6273\n",
            "Epoch 10/10\n",
            "54/54 [==============================] - 10s 176ms/step - loss: 1.6102\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).embedding_layer.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense_layer.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense_layer.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).embedding_layer.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense_layer.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense_layer.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2\n",
            "Alice constive as she well dens on the poor replied I waid the was new wanders. And I way, and goor downicsdleed. The $4A0, Duethed/, the Queen.-- \"There, with the White DaD’t couve--ald she said!\" Theull had here.) \"But and nace! Bie could her, ‘I don’t can it wout perain-the could gite redivand was shatay-taking on. Then other was her thould herself (she knot her th nead cary any gouse the poor, the staD VeqITY all hes ‘UNT it yourman toied seemed the Ploject Guten took amones as them, and faiting-by. The kempty margan with the mach doonon of sire found she said ‘I sny fe.\" Snate was the voiredly. I tream, and it?’ Eubp very CAlice chanded turning as shen off for him wit_ soldnering very teving up duiseph tim herself your Quet the. The King!’ ‘But worked to over; it littion. ‘Tho hors again a really dy grease she shat’s beadly that like it hat sitive some momedunur hived, and. (‘thos morermous walk. \"Thee, and compling templiss by it, for is againg exten have of the that now the Exnows: el\n",
            "---\n",
            "Epoch 1/10\n",
            "54/54 [==============================] - 10s 178ms/step - loss: 1.5935\n",
            "Epoch 2/10\n",
            "54/54 [==============================] - 10s 183ms/step - loss: 1.5793\n",
            "Epoch 3/10\n",
            "54/54 [==============================] - 10s 180ms/step - loss: 1.5681\n",
            "Epoch 4/10\n",
            "54/54 [==============================] - 10s 181ms/step - loss: 1.5519\n",
            "Epoch 5/10\n",
            "54/54 [==============================] - 10s 177ms/step - loss: 1.5405\n",
            "Epoch 6/10\n",
            "54/54 [==============================] - 10s 177ms/step - loss: 1.5337\n",
            "Epoch 7/10\n",
            "54/54 [==============================] - 10s 177ms/step - loss: 1.5180\n",
            "Epoch 8/10\n",
            "54/54 [==============================] - 10s 179ms/step - loss: 1.5097\n",
            "Epoch 9/10\n",
            "54/54 [==============================] - 10s 178ms/step - loss: 1.4996\n",
            "Epoch 10/10\n",
            "54/54 [==============================] - 10s 179ms/step - loss: 1.4988\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).embedding_layer.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense_layer.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense_layer.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).embedding_layer.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense_layer.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense_layer.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3\n",
            "Alice and she go quite open’t begish the Queen. ‘Was it was all uming--thing-some’s ME pay twm!’ no, you said how.\" \"It done used or hange jourd-- of the bittle \"and oncurain, whether courting or mestoan tims over, in me that she poor thure that here and that wwell fee, which felling under of when a little fell two Project, \"I’ll ghang, looking sprould a minute of you were word's chack opsed one Kittly come to see letten sure whilard and save or camest to get it againg out of cousty than the Dusped to Alice, ‘but they trembled and, is pars in sargething wonder, eysed to turnbely litt on herself was more though a do the morth three herself it was centene's like care, a dreamuse--- nothing eBook. ‘Why, all one saze it, him through it isped to ‘You 'TIMATY Listriadid never, with asked, and poap to bead going gryphing to lice ous--whall dee, when all is for way, and so ook it (ffres meciured refms and butine that went the kid), \"as execupty, and the ston; And pappying both to stap to it it fofte\n",
            "---\n",
            "Epoch 1/10\n",
            "54/54 [==============================] - 10s 177ms/step - loss: 1.4849\n",
            "Epoch 2/10\n",
            "54/54 [==============================] - 10s 178ms/step - loss: 1.4766\n",
            "Epoch 3/10\n",
            " 9/54 [====>.........................] - ETA: 7s - loss: 1.4611"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB0uVicfpt9q"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "samples = tf.random.categorical(tf.math.log([[0.5, 0.5]]), 1)\r\n",
        "samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "h6iYgBc4qKvu",
        "outputId": "1eeea29a-d5ae-4484-b134-b93b4728e67e"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-f7144498ec23>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    len(\"Alice and she go quite open’t begish the Queen. ‘Was it was all uming--thing-some’s ME pay twm!’ no, you said how.\" \"It done used or hange jourd-- of the bittle \"and oncurain, whether courting or mestoan tims over, in me that she poor thure that here and that wwell fee, which felling under of when a little fell two Project, \"I’ll ghang, looking sprould a minute of you were word's chack opsed one Kittly come to see letten sure whilard and save or camest to get it againg out of cousty than the Dusped to Alice, ‘but they trembled and, is pars in sargething wonder, eysed to turnbely litt on herself was more though a do the morth three herself it was centene's like care, a dreamuse--- nothing eBook. ‘Why, all one saze it, him through it isped to ‘You 'TIMATY Listriadid never, with asked, and poap to bead going gryphing to lice ous--whall dee, when all is for way, and so ook it (ffres meciured refms and butine that went the kid), \"as execupty, and the ston; And pappying both to stap to it it fofte\u001b[0m\n\u001b[0m                                                                                                                                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}